{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3facbdf-9531-449c-a228-956b40a2b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables from the .env file\n",
    "# pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e63c5d-c975-4482-86f2-227bd08d9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using langchain API\n",
    "# pip install langchain openai\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "model = OpenAI() # requires 'OPENAI_API_KEY' env var to be set (! echo $OPENAI_API_KEY to see the key)\n",
    "response = model(\"what colors can dogs see?\")\n",
    "response.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d9aa7-673a-48de-8f5f-f506cce6c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using openai directly\n",
    "# pip install openai\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI() #requires 'OPENAI_API_KEY' env var to be set\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"what colors can dogs see?\",\n",
    "        }\n",
    "    ],\n",
    "    model = \"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad005c-9d18-4945-8b4f-4f6cf3d4df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG - Retrieval Augumented Generation\n",
    "# pip install requests beautifulsoup4 sentence-transformers faiss-cpu openai\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import faiss\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "\n",
    "def get_answer(query, url):\n",
    "    # Download contents of a web page\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Generate Text Embeddings from the web page content\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2') # Downloads the embedding model from the internet\n",
    "    sentences = text.split('.')\n",
    "    sentences = [re.sub(r'\\s+', ' ', s) for s in sentences]\n",
    "    embeddings = model.encode(sentences) # One embedding per sentence\n",
    "    \n",
    "    # Storing and Indexing Content to a Vector Database (using FAISS for now, can use any vector db)\n",
    "    \n",
    "    # Initialize a FAISS index\n",
    "    dimension = embeddings.shape[1]  # Dimension of the embeddings\n",
    "    base_index = faiss.IndexFlatL2(dimension)\n",
    "    index = faiss.IndexIDMap(base_index) # So that we can save an id in the index\n",
    "    \n",
    "    # Todo : save the senteneces somewhere permanent and then use the permanent ids instead.\n",
    "    \n",
    "    # Add vectors to the index\n",
    "    ids = np.arange(len(embeddings))\n",
    "    index.add_with_ids(np.array(embeddings).astype('float32'), ids)\n",
    "    \n",
    "    # Find ids of embeddings from the index which are close to the query\n",
    "    query_embedding = model.encode([query])\n",
    "    distances, indices = index.search(query_embedding.astype('float32'), k=3)\n",
    "    \n",
    "    debug=False\n",
    "    if debug:\n",
    "        # Print top k similar sentences\n",
    "        for i in indices[0]: # Since we only have one item in [query] use 'indices[0]'\n",
    "            print(sentences[i])\n",
    "            print('-'*50)\n",
    "    \n",
    "    context = \".\".join([sentences[i] for i in indices[0]])\n",
    "    \n",
    "    # Do an LLM Query with the context\n",
    "    client = OpenAI()  # requires 'OPENAI_API_KEY' env var to be set\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {query} \\n Use the following context if it is helpful: {context}\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Use the contents of the URL to get answer to the question\n",
    "query = \"What is work study position\"\n",
    "url = \"https://studentlife.utoronto.ca/news/work-study-is-back-for-september-2022/\"\n",
    "query = \"Why are stripped stars difficult to find?\"\n",
    "url = \"https://www.utoronto.ca/news/u-t-astronomers-discover-first-population-binary-stripped-stars\"\n",
    "\n",
    "get_answer(query, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa69437-d151-42f2-922a-324c175f4acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
